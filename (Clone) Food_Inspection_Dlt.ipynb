{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "523f1fd5-edea-42d8-94a0-840df5fbc0f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "@dlt.table(\n",
    "    name=\"bronze_chicago_raw\",\n",
    "    comment=\"Raw Chicago food inspections from multiple TSV files.\"\n",
    ")\n",
    "def bronze_chicago_raw():\n",
    "    base_path = \"/Volumes/food_inspections_catalog/bronze/raw_data/\"\n",
    "    chicago_files = [\n",
    "        f\"{base_path}Chicago_2021-2022.tsv\",\n",
    "        f\"{base_path}Chicago_2022-2023.tsv\",\n",
    "        f\"{base_path}Chicago_2023-2024.tsv\",\n",
    "        f\"{base_path}Chicago_2024-2025.tsv\",\n",
    "        f\"{base_path}Chicago_2025-partyear.tsv\"\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"delimiter\", \"\\t\")\n",
    "        .option(\"multiLine\", True)\n",
    "        .csv(chicago_files)\n",
    "    )\n",
    "\n",
    "    df = df.toDF(*[re.sub(r'[^A-Za-z0-9_]', '_', c.strip().replace(' ', '_')) for c in df.columns])\n",
    "\n",
    "    return df.withColumn(\"source_city\", F.lit(\"Chicago\"))\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_dallas_raw\",\n",
    "    comment=\"Raw Dallas food inspections from multiple TSV files.\"\n",
    ")\n",
    "def bronze_dallas_raw():\n",
    "    base_path = \"/Volumes/food_inspections_catalog/bronze/raw_data/\"\n",
    "    dallas_files = [\n",
    "        f\"{base_path}Dallas_2021-2022.tsv\",\n",
    "        f\"{base_path}Dallas_2022-2023.tsv\",\n",
    "        f\"{base_path}Dallas_2023-2024.tsv\",\n",
    "        f\"{base_path}Dallas_2024-2025.tsv\",\n",
    "        f\"{base_path}Dallas_2025-partyear.tsv\"\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"delimiter\", \"\\t\")\n",
    "        .option(\"multiLine\", True)\n",
    "        .csv(dallas_files)\n",
    "    )\n",
    "    df = df.toDF(*[re.sub(r'[^A-Za-z0-9_]', '_', c.strip().replace(' ', '_')) for c in df.columns])\n",
    "\n",
    "    return df.withColumn(\"source_city\", F.lit(\"Dallas\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef8d64f2-59e4-48c1-9ec6-54ebd97b05c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_chicago_clean\",\n",
    "    comment=\"Cleansed Chicago food inspection data with derived violation score and validation rules.\"\n",
    ")\n",
    "@dlt.expect_all_or_drop({\n",
    "    \"non_null_fields\": \"DBA_Name IS NOT NULL AND Inspection_Date IS NOT NULL AND Inspection_Type IS NOT NULL AND Zip IS NOT NULL AND Results IS NOT NULL\",\n",
    "    \"valid_zip\": \"Zip RLIKE '^[0-9]{5}$'\"\n",
    "})\n",
    "def silver_chicago_clean():\n",
    "    df = dlt.read(\"bronze_chicago_raw\")\n",
    "\n",
    "    df = (\n",
    "        df.withColumn(\"Zip\", F.trim(\"Zip\"))\n",
    "          .withColumn(\"Zip\", F.regexp_extract(F.col(\"Zip\"), r\"(\\d{5})\", 1))\n",
    "          .withColumn(\"Inspection_Date\", F.to_date(\"Inspection_Date\"))\n",
    "          .withColumn(\"Results\", F.trim(\"Results\"))\n",
    "          .withColumn(\"Facility_Type\", F.trim(\"Facility_Type\"))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"Violation_Score\",\n",
    "        F.when(F.col(\"Results\") == \"Pass\", 90)\n",
    "         .when(F.col(\"Results\") == \"Pass w/ Conditions\", 80)\n",
    "         .when(F.col(\"Results\") == \"Fail\", 70)\n",
    "         .when(F.col(\"Results\") == \"No Entry\", 0)\n",
    "         .otherwise(None)\n",
    "    )\n",
    "\n",
    "    return df.dropDuplicates([\"Inspection_Date\", \"License__\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8101b934-0902-4b46-95d6-051182b2199d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_dallas_clean\",\n",
    "    comment=\"Cleansed Dallas food inspection data standardized to match Chicago schema.\"\n",
    ")\n",
    "@dlt.expect_all_or_drop({\n",
    "    \"non_null_fields\": \"Inspection_Date IS NOT NULL\"\n",
    "})\n",
    "def silver_dallas_clean():\n",
    "    df = dlt.read(\"bronze_dallas_raw\")\n",
    "\n",
    "    col_map = {\n",
    "        \"Restaurant_Name\": \"DBA_Name\",\n",
    "        \"Business_Name\": \"DBA_Name\",\n",
    "        \"Inspection_Score\": \"Violation_Score\",\n",
    "        \"Score\": \"Violation_Score\",\n",
    "        \"Inspection_Date\": \"Inspection_Date\",\n",
    "        \"Date\": \"Inspection_Date\",\n",
    "        \"Inspection_Type\": \"Inspection_Type\",\n",
    "        \"Zip_Code\": \"Zip\",\n",
    "        \"ZipCode\": \"Zip\"\n",
    "    }\n",
    "\n",
    "    for old, new in col_map.items():\n",
    "        if old in df.columns:\n",
    "            df = df.withColumnRenamed(old, new)\n",
    "\n",
    "    address_parts = []\n",
    "    for part in [\"Street_Number\", \"Street_Name\", \"Street_Type\"]:\n",
    "        if part in df.columns:\n",
    "            address_parts.append(F.col(part))\n",
    "    if address_parts:\n",
    "        df = df.withColumn(\"Address\", F.concat_ws(\" \", *address_parts))\n",
    "    else:\n",
    "        df = df.withColumn(\"Address\", F.lit(None).cast(\"string\"))\n",
    "\n",
    "    required_cols = [\"DBA_Name\", \"Address\", \"Zip\", \"Inspection_Date\", \"Inspection_Type\", \"Violation_Score\"]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            df = df.withColumn(c, F.lit(None).cast(\"string\"))\n",
    "\n",
    "    df = (\n",
    "        df.withColumn(\"Facility_Type\", F.lit(\"Restaurant\"))\n",
    "          .withColumn(\"City\", F.lit(\"Dallas\"))\n",
    "          .withColumn(\"State\", F.lit(\"TX\"))\n",
    "          .withColumn(\"source_city\", F.lit(\"Dallas\"))\n",
    "          .withColumn(\"Inspection_Date\", F.to_date(\"Inspection_Date\"))\n",
    "          .withColumn(\"Zip\", F.regexp_extract(F.col(\"Zip\"), r\"(\\d{5})\", 1))\n",
    "          .withColumn(\"Violation_Score\", F.col(\"Violation_Score\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    return df.dropDuplicates([\"DBA_Name\", \"Address\", \"Inspection_Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b871692a-8a7f-46c8-a343-58bf41b6083a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"dim_facility\",\n",
    "    comment=\"Facility dimension combining Chicago and Dallas data with SCD Type 2 tracking.\"\n",
    ")\n",
    "def dim_facility():\n",
    "    chi = (\n",
    "        dlt.read(\"silver_chicago_clean\")\n",
    "        .select(\n",
    "            F.col(\"License__\").alias(\"facility_id\"),\n",
    "            F.col(\"DBA_Name\").alias(\"facility_name\"),\n",
    "            F.col(\"Facility_Type\").alias(\"facility_type\"),\n",
    "            F.lit(\"Chicago\").alias(\"city\"),\n",
    "            F.col(\"Inspection_Date\").alias(\"effective_date\")\n",
    "        ).dropna(subset=[\"facility_name\"])\n",
    "    )\n",
    "\n",
    "    dal = (\n",
    "        dlt.read(\"silver_dallas_clean\")\n",
    "        .select(\n",
    "            F.monotonically_increasing_id().alias(\"facility_id\"),\n",
    "            F.col(\"DBA_Name\").alias(\"facility_name\"),\n",
    "            F.col(\"Facility_Type\").alias(\"facility_type\"),\n",
    "            F.lit(\"Dallas\").alias(\"city\"),\n",
    "            F.col(\"Inspection_Date\").alias(\"effective_date\")\n",
    "        ).dropna(subset=[\"facility_name\"])\n",
    "    )\n",
    "\n",
    "    df = chi.unionByName(dal, allowMissingColumns=True)\n",
    "    w = Window.partitionBy(\"facility_id\").orderBy(\"effective_date\")\n",
    "\n",
    "    return (\n",
    "        df.withColumn(\"start_date\", F.col(\"effective_date\"))\n",
    "          .withColumn(\"end_date\", F.lead(\"effective_date\").over(w))\n",
    "          .withColumn(\"is_current\", F.when(F.col(\"end_date\").isNull(), True).otherwise(False))\n",
    "          .dropDuplicates([\"facility_id\", \"facility_name\", \"facility_type\", \"city\", \"effective_date\"])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d207828-bbf2-41ae-be80-c1b5f3cb93b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"dim_location\",\n",
    "    comment=\"Location dimension combining ZIP, city, and state across Chicago and Dallas.\"\n",
    ")\n",
    "def dim_location():\n",
    "    chi = (\n",
    "        dlt.read(\"silver_chicago_clean\")\n",
    "        .select(F.col(\"Zip\").alias(\"zip_code\"), F.col(\"City\").alias(\"city\"), F.col(\"State\").alias(\"state\"))\n",
    "    )\n",
    "    dal = (\n",
    "        dlt.read(\"silver_dallas_clean\")\n",
    "        .select(F.col(\"Zip\").alias(\"zip_code\"), F.col(\"City\").alias(\"city\"), F.col(\"State\").alias(\"state\"))\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        chi.unionByName(dal, allowMissingColumns=True)\n",
    "           .filter(F.col(\"zip_code\").isNotNull())\n",
    "           .dropDuplicates([\"zip_code\"])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50263f2b-efc8-4119-b54e-08a2b39be605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"dim_date\",\n",
    "    comment=\"Date dimension for all inspection records.\"\n",
    ")\n",
    "def dim_date():\n",
    "    chi = dlt.read(\"silver_chicago_clean\").select(F.col(\"Inspection_Date\").alias(\"date\"))\n",
    "    dal = dlt.read(\"silver_dallas_clean\").select(F.col(\"Inspection_Date\").alias(\"date\"))\n",
    "\n",
    "    return (\n",
    "        chi.unionByName(dal, allowMissingColumns=True)\n",
    "           .filter(F.col(\"date\").isNotNull())\n",
    "           .dropDuplicates([\"date\"])\n",
    "           .withColumn(\"year\", F.year(\"date\"))\n",
    "           .withColumn(\"month\", F.month(\"date\"))\n",
    "           .withColumn(\"day\", F.dayofmonth(\"date\"))\n",
    "           .withColumn(\"weekday\", F.date_format(\"date\", \"EEEE\"))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c266c2e-a949-42a9-b57c-e9980b706b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"fact_inspection\",\n",
    "    comment=\"Fact table combining all inspection events from both cities.\"\n",
    ")\n",
    "def fact_inspection():\n",
    "    chi = (\n",
    "        dlt.read(\"silver_chicago_clean\")\n",
    "        .select(\n",
    "            F.col(\"Inspection_ID\").alias(\"inspection_id\"),\n",
    "            F.col(\"License__\").alias(\"facility_id\"),\n",
    "            F.col(\"Inspection_Date\").alias(\"inspection_date\"),\n",
    "            F.col(\"Inspection_Type\").alias(\"inspection_type\"),\n",
    "            F.col(\"Results\").alias(\"result\"),\n",
    "            F.col(\"Violation_Score\").alias(\"violation_score\"),\n",
    "            F.col(\"Risk\").alias(\"risk_level\"),\n",
    "            F.col(\"Zip\").alias(\"zip_code\"),\n",
    "            F.col(\"source_city\").alias(\"city\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dal_src = dlt.read(\"silver_dallas_clean\")\n",
    "    if \"Results\" not in dal_src.columns:\n",
    "        dal_src = dal_src.withColumn(\"Results\", F.lit(None).cast(\"string\"))\n",
    "    if \"Inspection_Type\" not in dal_src.columns:\n",
    "        dal_src = dal_src.withColumn(\"Inspection_Type\", F.lit(None).cast(\"string\"))\n",
    "\n",
    "    dal = (\n",
    "        dal_src\n",
    "        .withColumn(\n",
    "            \"inspection_id\",\n",
    "            F.md5(F.concat_ws(\"|\", F.col(\"DBA_Name\"), F.col(\"Address\"), F.col(\"Inspection_Date\").cast(\"string\")))\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"inspection_id\"),\n",
    "            F.md5(F.concat_ws(\"|\", F.col(\"DBA_Name\"), F.col(\"Address\"))).alias(\"facility_id\"),\n",
    "            F.col(\"Inspection_Date\").alias(\"inspection_date\"),\n",
    "            F.col(\"Inspection_Type\").alias(\"inspection_type\"),\n",
    "            F.col(\"Results\").alias(\"result\"),\n",
    "            F.col(\"Violation_Score\").alias(\"violation_score\"),\n",
    "            F.lit(None).alias(\"risk_level\"),\n",
    "            F.col(\"Zip\").alias(\"zip_code\"),\n",
    "            F.col(\"source_city\").alias(\"city\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return chi.unionByName(dal, allowMissingColumns=True)  \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Food_Inspection_Dlt",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
